digraph {
	graph [size="65.25,65.25"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2566472302032 [label="
 (10, 1, 20)" fillcolor=darkolivegreen1]
	2567529259280 [label=PermuteBackward0]
	2567529251072 -> 2567529259280
	2567529251072 [label=ViewBackward0]
	2567529259568 -> 2567529251072
	2567529259568 [label=AddmmBackward0]
	2567529259760 -> 2567529259568
	2567195430720 [label="linear2.bias
 (20)" fillcolor=lightblue]
	2567195430720 -> 2567529259760
	2567529259760 [label=AccumulateGrad]
	2567529259232 -> 2567529259568
	2567529259232 [label=ViewBackward0]
	2567529251936 -> 2567529259232
	2567529251936 [label=CudnnRnnBackward0]
	2567529252224 -> 2567529251936
	2567529252224 [label=AddBackward0]
	2567529259904 -> 2567529252224
	2567529259904 [label=SliceBackward0]
	2567529260480 -> 2567529259904
	2567529260480 [label=SliceBackward0]
	2567529251456 -> 2567529260480
	2567529251456 [label=SliceBackward0]
	2567529264944 -> 2567529251456
	2567529264944 [label=CudnnRnnBackward0]
	2567529264560 -> 2567529264944
	2567529264560 [label=AddBackward0]
	2567529259952 -> 2567529264560
	2567529259952 [label=UnsafeViewBackward0]
	2567529260144 -> 2567529259952
	2567529260144 [label=MmBackward0]
	2567529260000 -> 2567529260144
	2567529260000 [label=ReshapeAliasBackward0]
	2567529256784 -> 2567529260000
	2567529256784 [label=ViewBackward0]
	2567529257072 -> 2567529256784
	2567529257072 [label=PermuteBackward0]
	2567529256352 -> 2567529257072
	2567529256352 [label=ReluBackward0]
	2567529256448 -> 2567529256352
	2567529256448 [label=CudnnBatchNormBackward0]
	2567529255536 -> 2567529256448
	2567529255536 [label=ConvolutionBackward0]
	2567529258800 -> 2567529255536
	2567529258800 [label=ReluBackward0]
	2567529258656 -> 2567529258800
	2567529258656 [label=AddBackward0]
	2567529258512 -> 2567529258656
	2567529258512 [label=CudnnBatchNormBackward0]
	2567529255920 -> 2567529258512
	2567529255920 [label=ConvolutionBackward0]
	2567529258416 -> 2567529255920
	2567529258416 [label=ReluBackward0]
	2567529258224 -> 2567529258416
	2567529258224 [label=CudnnBatchNormBackward0]
	2567529258176 -> 2567529258224
	2567529258176 [label=ConvolutionBackward0]
	2567529258560 -> 2567529258176
	2567529258560 [label=ReluBackward0]
	2567529257648 -> 2567529258560
	2567529257648 [label=AddBackward0]
	2567529257600 -> 2567529257648
	2567529257600 [label=CudnnBatchNormBackward0]
	2567529257456 -> 2567529257600
	2567529257456 [label=ConvolutionBackward0]
	2567529257312 -> 2567529257456
	2567529257312 [label=ReluBackward0]
	2567529257120 -> 2567529257312
	2567529257120 [label=CudnnBatchNormBackward0]
	2567529257984 -> 2567529257120
	2567529257984 [label=ConvolutionBackward0]
	2567529255824 -> 2567529257984
	2567529255824 [label=ReluBackward0]
	2567529256064 -> 2567529255824
	2567529256064 [label=AddBackward0]
	2567529255968 -> 2567529256064
	2567529255968 [label=CudnnBatchNormBackward0]
	2567529266960 -> 2567529255968
	2567529266960 [label=ConvolutionBackward0]
	2567529263744 -> 2567529266960
	2567529263744 [label=ReluBackward0]
	2567529267104 -> 2567529263744
	2567529267104 [label=CudnnBatchNormBackward0]
	2567529267152 -> 2567529267104
	2567529267152 [label=ConvolutionBackward0]
	2567529256016 -> 2567529267152
	2567529256016 [label=ReluBackward0]
	2567529255200 -> 2567529256016
	2567529255200 [label=AddBackward0]
	2567529255152 -> 2567529255200
	2567529255152 [label=CudnnBatchNormBackward0]
	2567529252464 -> 2567529255152
	2567529252464 [label=ConvolutionBackward0]
	2567529252032 -> 2567529252464
	2567529252032 [label=ReluBackward0]
	2567529252368 -> 2567529252032
	2567529252368 [label=CudnnBatchNormBackward0]
	2567529252080 -> 2567529252368
	2567529252080 [label=ConvolutionBackward0]
	2567529254960 -> 2567529252080
	2567529254960 [label=ReluBackward0]
	2567529254816 -> 2567529254960
	2567529254816 [label=AddBackward0]
	2567529254720 -> 2567529254816
	2567529254720 [label=CudnnBatchNormBackward0]
	2567529254576 -> 2567529254720
	2567529254576 [label=ConvolutionBackward0]
	2567529254384 -> 2567529254576
	2567529254384 [label=ReluBackward0]
	2567529253472 -> 2567529254384
	2567529253472 [label=CudnnBatchNormBackward0]
	2567529253328 -> 2567529253472
	2567529253328 [label=ConvolutionBackward0]
	2567529254768 -> 2567529253328
	2567529254768 [label=ReluBackward0]
	2567529253088 -> 2567529254768
	2567529253088 [label=AddBackward0]
	2567529252944 -> 2567529253088
	2567529252944 [label=CudnnBatchNormBackward0]
	2567529252848 -> 2567529252944
	2567529252848 [label=ConvolutionBackward0]
	2567529254192 -> 2567529252848
	2567529254192 [label=ReluBackward0]
	2567529254048 -> 2567529254192
	2567529254048 [label=CudnnBatchNormBackward0]
	2567529253952 -> 2567529254048
	2567529253952 [label=ConvolutionBackward0]
	2567529253040 -> 2567529253952
	2567529253040 [label=MaxPool2DWithIndicesBackward0]
	2567529253664 -> 2567529253040
	2567529253664 [label=ReluBackward0]
	2567529253568 -> 2567529253664
	2567529253568 [label=CudnnBatchNormBackward0]
	2567529262352 -> 2567529253568
	2567529262352 [label=ConvolutionBackward0]
	2567529258896 -> 2567529262352
	2567195270240 [label="cnn_p1.0.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	2567195270240 -> 2567529258896
	2567529258896 [label=AccumulateGrad]
	2567529262304 -> 2567529253568
	2567195270320 [label="cnn_p1.1.weight
 (64)" fillcolor=lightblue]
	2567195270320 -> 2567529262304
	2567529262304 [label=AccumulateGrad]
	2567529253856 -> 2567529253568
	2567195270400 [label="cnn_p1.1.bias
 (64)" fillcolor=lightblue]
	2567195270400 -> 2567529253856
	2567529253856 [label=AccumulateGrad]
	2567529253712 -> 2567529253952
	2567195271120 [label="cnn_p1.4.0.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2567195271120 -> 2567529253712
	2567529253712 [label=AccumulateGrad]
	2567529254000 -> 2567529254048
	2567195271040 [label="cnn_p1.4.0.bn1.weight
 (64)" fillcolor=lightblue]
	2567195271040 -> 2567529254000
	2567529254000 [label=AccumulateGrad]
	2567529254096 -> 2567529254048
	2567195271200 [label="cnn_p1.4.0.bn1.bias
 (64)" fillcolor=lightblue]
	2567195271200 -> 2567529254096
	2567529254096 [label=AccumulateGrad]
	2567529254240 -> 2567529252848
	2567195271760 [label="cnn_p1.4.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2567195271760 -> 2567529254240
	2567529254240 [label=AccumulateGrad]
	2567529252896 -> 2567529252944
	2567195271680 [label="cnn_p1.4.0.bn2.weight
 (64)" fillcolor=lightblue]
	2567195271680 -> 2567529252896
	2567529252896 [label=AccumulateGrad]
	2567529252992 -> 2567529252944
	2567195271840 [label="cnn_p1.4.0.bn2.bias
 (64)" fillcolor=lightblue]
	2567195271840 -> 2567529252992
	2567529252992 [label=AccumulateGrad]
	2567529253040 -> 2567529253088
	2567529253184 -> 2567529253328
	2567195272240 [label="cnn_p1.4.1.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2567195272240 -> 2567529253184
	2567529253184 [label=AccumulateGrad]
	2567529253424 -> 2567529253472
	2567195272160 [label="cnn_p1.4.1.bn1.weight
 (64)" fillcolor=lightblue]
	2567195272160 -> 2567529253424
	2567529253424 [label=AccumulateGrad]
	2567529254336 -> 2567529253472
	2567195272320 [label="cnn_p1.4.1.bn1.bias
 (64)" fillcolor=lightblue]
	2567195272320 -> 2567529254336
	2567529254336 [label=AccumulateGrad]
	2567529254432 -> 2567529254576
	2567195272880 [label="cnn_p1.4.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2567195272880 -> 2567529254432
	2567529254432 [label=AccumulateGrad]
	2567529254624 -> 2567529254720
	2567195272800 [label="cnn_p1.4.1.bn2.weight
 (64)" fillcolor=lightblue]
	2567195272800 -> 2567529254624
	2567529254624 [label=AccumulateGrad]
	2567529254672 -> 2567529254720
	2567195272960 [label="cnn_p1.4.1.bn2.bias
 (64)" fillcolor=lightblue]
	2567195272960 -> 2567529254672
	2567529254672 [label=AccumulateGrad]
	2567529254768 -> 2567529254816
	2567529255008 -> 2567529252080
	2567195274000 [label="cnn_p1.5.0.conv1.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	2567195274000 -> 2567529255008
	2567529255008 [label=AccumulateGrad]
	2567529251648 -> 2567529252368
	2567195273920 [label="cnn_p1.5.0.bn1.weight
 (128)" fillcolor=lightblue]
	2567195273920 -> 2567529251648
	2567529251648 [label=AccumulateGrad]
	2567529252320 -> 2567529252368
	2567195274080 [label="cnn_p1.5.0.bn1.bias
 (128)" fillcolor=lightblue]
	2567195274080 -> 2567529252320
	2567529252320 [label=AccumulateGrad]
	2567529252608 -> 2567529252464
	2567195274640 [label="cnn_p1.5.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2567195274640 -> 2567529252608
	2567529252608 [label=AccumulateGrad]
	2567529252176 -> 2567529255152
	2567195274560 [label="cnn_p1.5.0.bn2.weight
 (128)" fillcolor=lightblue]
	2567195274560 -> 2567529252176
	2567529252176 [label=AccumulateGrad]
	2567529255104 -> 2567529255152
	2567195274720 [label="cnn_p1.5.0.bn2.bias
 (128)" fillcolor=lightblue]
	2567195274720 -> 2567529255104
	2567529255104 [label=AccumulateGrad]
	2567529255248 -> 2567529255200
	2567529255248 [label=CudnnBatchNormBackward0]
	2567529255056 -> 2567529255248
	2567529255056 [label=ConvolutionBackward0]
	2567529254960 -> 2567529255056
	2567529254864 -> 2567529255056
	2567195273280 [label="cnn_p1.5.0.downsample.0.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	2567195273280 -> 2567529254864
	2567529254864 [label=AccumulateGrad]
	2567529252752 -> 2567529255248
	2567195271360 [label="cnn_p1.5.0.downsample.1.weight
 (128)" fillcolor=lightblue]
	2567195271360 -> 2567529252752
	2567529252752 [label=AccumulateGrad]
	2567529252272 -> 2567529255248
	2567195273360 [label="cnn_p1.5.0.downsample.1.bias
 (128)" fillcolor=lightblue]
	2567195273360 -> 2567529252272
	2567529252272 [label=AccumulateGrad]
	2567529255344 -> 2567529267152
	2567195275200 [label="cnn_p1.5.1.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2567195275200 -> 2567529255344
	2567529255344 [label=AccumulateGrad]
	2567529266912 -> 2567529267104
	2567195275120 [label="cnn_p1.5.1.bn1.weight
 (128)" fillcolor=lightblue]
	2567195275120 -> 2567529266912
	2567529266912 [label=AccumulateGrad]
	2567529266720 -> 2567529267104
	2567195275280 [label="cnn_p1.5.1.bn1.bias
 (128)" fillcolor=lightblue]
	2567195275280 -> 2567529266720
	2567529266720 [label=AccumulateGrad]
	2567529263840 -> 2567529266960
	2567195275840 [label="cnn_p1.5.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2567195275840 -> 2567529263840
	2567529263840 [label=AccumulateGrad]
	2567529266816 -> 2567529255968
	2567195275760 [label="cnn_p1.5.1.bn2.weight
 (128)" fillcolor=lightblue]
	2567195275760 -> 2567529266816
	2567529266816 [label=AccumulateGrad]
	2567529257792 -> 2567529255968
	2567195275920 [label="cnn_p1.5.1.bn2.bias
 (128)" fillcolor=lightblue]
	2567195275920 -> 2567529257792
	2567529257792 [label=AccumulateGrad]
	2567529256016 -> 2567529256064
	2567529257888 -> 2567529257984
	2567195277200 [label="cnn_p1.6.0.conv1.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	2567195277200 -> 2567529257888
	2567529257888 [label=AccumulateGrad]
	2567529258032 -> 2567529257120
	2567195277120 [label="cnn_p1.6.0.bn1.weight
 (256)" fillcolor=lightblue]
	2567195277120 -> 2567529258032
	2567529258032 [label=AccumulateGrad]
	2567529257216 -> 2567529257120
	2567195277280 [label="cnn_p1.6.0.bn1.bias
 (256)" fillcolor=lightblue]
	2567195277280 -> 2567529257216
	2567529257216 [label=AccumulateGrad]
	2567529257264 -> 2567529257456
	2567195277840 [label="cnn_p1.6.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2567195277840 -> 2567529257264
	2567529257264 [label=AccumulateGrad]
	2567529257504 -> 2567529257600
	2567195277760 [label="cnn_p1.6.0.bn2.weight
 (256)" fillcolor=lightblue]
	2567195277760 -> 2567529257504
	2567529257504 [label=AccumulateGrad]
	2567529257552 -> 2567529257600
	2567195277920 [label="cnn_p1.6.0.bn2.bias
 (256)" fillcolor=lightblue]
	2567195277920 -> 2567529257552
	2567529257552 [label=AccumulateGrad]
	2567529257696 -> 2567529257648
	2567529257696 [label=CudnnBatchNormBackward0]
	2567529257840 -> 2567529257696
	2567529257840 [label=ConvolutionBackward0]
	2567529255824 -> 2567529257840
	2567529255776 -> 2567529257840
	2567195276400 [label="cnn_p1.6.0.downsample.0.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	2567195276400 -> 2567529255776
	2567529255776 [label=AccumulateGrad]
	2567529257360 -> 2567529257696
	2567195276480 [label="cnn_p1.6.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	2567195276480 -> 2567529257360
	2567529257360 [label=AccumulateGrad]
	2567529257408 -> 2567529257696
	2567195276560 [label="cnn_p1.6.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	2567195276560 -> 2567529257408
	2567529257408 [label=AccumulateGrad]
	2567529250976 -> 2567529258176
	2567195278400 [label="cnn_p1.6.1.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2567195278400 -> 2567529250976
	2567529250976 [label=AccumulateGrad]
	2567529258272 -> 2567529258224
	2567195278320 [label="cnn_p1.6.1.bn1.weight
 (256)" fillcolor=lightblue]
	2567195278320 -> 2567529258272
	2567529258272 [label=AccumulateGrad]
	2567529258368 -> 2567529258224
	2567195278480 [label="cnn_p1.6.1.bn1.bias
 (256)" fillcolor=lightblue]
	2567195278480 -> 2567529258368
	2567529258368 [label=AccumulateGrad]
	2567529255584 -> 2567529255920
	2567195279040 [label="cnn_p1.6.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2567195279040 -> 2567529255584
	2567529255584 [label=AccumulateGrad]
	2567529255872 -> 2567529258512
	2567195278960 [label="cnn_p1.6.1.bn2.weight
 (256)" fillcolor=lightblue]
	2567195278960 -> 2567529255872
	2567529255872 [label=AccumulateGrad]
	2567529258464 -> 2567529258512
	2567195279120 [label="cnn_p1.6.1.bn2.bias
 (256)" fillcolor=lightblue]
	2567195279120 -> 2567529258464
	2567529258464 [label=AccumulateGrad]
	2567529258560 -> 2567529258656
	2567529256160 -> 2567529255536
	2567195438480 [label="cnn_p2.0.weight
 (256, 256, 3, 6)" fillcolor=lightblue]
	2567195438480 -> 2567529256160
	2567529256160 [label=AccumulateGrad]
	2567529256400 -> 2567529255536
	2567195438880 [label="cnn_p2.0.bias
 (256)" fillcolor=lightblue]
	2567195438880 -> 2567529256400
	2567529256400 [label=AccumulateGrad]
	2567529256688 -> 2567529256448
	2567195275440 [label="cnn_p2.1.weight
 (256)" fillcolor=lightblue]
	2567195275440 -> 2567529256688
	2567529256688 [label=AccumulateGrad]
	2567529255440 -> 2567529256448
	2566914677056 [label="cnn_p2.1.bias
 (256)" fillcolor=lightblue]
	2566914677056 -> 2567529255440
	2567529255440 [label=AccumulateGrad]
	2567529260192 -> 2567529260144
	2567529260192 [label=TBackward0]
	2567529256928 -> 2567529260192
	2567195433440 [label="linear1.weight
 (256, 1024)" fillcolor=lightblue]
	2567195433440 -> 2567529256928
	2567529256928 [label=AccumulateGrad]
	2567529259664 -> 2567529264560
	2567195436000 [label="linear1.bias
 (256)" fillcolor=lightblue]
	2567195436000 -> 2567529259664
	2567529259664 [label=AccumulateGrad]
	2567529265040 -> 2567529264944
	2567075618048 [label="rnn1.weight_ih_l0
 (768, 256)" fillcolor=lightblue]
	2567075618048 -> 2567529265040
	2567529265040 [label=AccumulateGrad]
	2567529259856 -> 2567529264944
	2567195435840 [label="rnn1.weight_hh_l0
 (768, 256)" fillcolor=lightblue]
	2567195435840 -> 2567529259856
	2567529259856 [label=AccumulateGrad]
	2567529259328 -> 2567529264944
	2567195436800 [label="rnn1.bias_ih_l0
 (768)" fillcolor=lightblue]
	2567195436800 -> 2567529259328
	2567529259328 [label=AccumulateGrad]
	2567529259424 -> 2567529264944
	2567195441360 [label="rnn1.bias_hh_l0
 (768)" fillcolor=lightblue]
	2567195441360 -> 2567529259424
	2567529259424 [label=AccumulateGrad]
	2567529259472 -> 2567529264944
	2567195436400 [label="rnn1.weight_ih_l0_reverse
 (768, 256)" fillcolor=lightblue]
	2567195436400 -> 2567529259472
	2567529259472 [label=AccumulateGrad]
	2567529259184 -> 2567529264944
	2567195439120 [label="rnn1.weight_hh_l0_reverse
 (768, 256)" fillcolor=lightblue]
	2567195439120 -> 2567529259184
	2567529259184 [label=AccumulateGrad]
	2567529260288 -> 2567529264944
	2567195438800 [label="rnn1.bias_ih_l0_reverse
 (768)" fillcolor=lightblue]
	2567195438800 -> 2567529260288
	2567529260288 [label=AccumulateGrad]
	2567529260384 -> 2567529264944
	2567195439200 [label="rnn1.bias_hh_l0_reverse
 (768)" fillcolor=lightblue]
	2567195439200 -> 2567529260384
	2567529260384 [label=AccumulateGrad]
	2567529256736 -> 2567529252224
	2567529256736 [label=SliceBackward0]
	2567529264656 -> 2567529256736
	2567529264656 [label=SliceBackward0]
	2567529260240 -> 2567529264656
	2567529260240 [label=SliceBackward0]
	2567529264944 -> 2567529260240
	2567529252512 -> 2567529251936
	2567195434240 [label="rnn2.weight_ih_l0
 (768, 256)" fillcolor=lightblue]
	2567195434240 -> 2567529252512
	2567529252512 [label=AccumulateGrad]
	2567529252560 -> 2567529251936
	2567195437360 [label="rnn2.weight_hh_l0
 (768, 256)" fillcolor=lightblue]
	2567195437360 -> 2567529252560
	2567529252560 [label=AccumulateGrad]
	2567529252704 -> 2567529251936
	2567195436160 [label="rnn2.bias_ih_l0
 (768)" fillcolor=lightblue]
	2567195436160 -> 2567529252704
	2567529252704 [label=AccumulateGrad]
	2567529252656 -> 2567529251936
	2567195435200 [label="rnn2.bias_hh_l0
 (768)" fillcolor=lightblue]
	2567195435200 -> 2567529252656
	2567529252656 [label=AccumulateGrad]
	2567529252416 -> 2567529251936
	2567195433600 [label="rnn2.weight_ih_l0_reverse
 (768, 256)" fillcolor=lightblue]
	2567195433600 -> 2567529252416
	2567529252416 [label=AccumulateGrad]
	2567529256880 -> 2567529251936
	2567195434000 [label="rnn2.weight_hh_l0_reverse
 (768, 256)" fillcolor=lightblue]
	2567195434000 -> 2567529256880
	2567529256880 [label=AccumulateGrad]
	2567529256832 -> 2567529251936
	2567195432560 [label="rnn2.bias_ih_l0_reverse
 (768)" fillcolor=lightblue]
	2567195432560 -> 2567529256832
	2567529256832 [label=AccumulateGrad]
	2567529256544 -> 2567529251936
	2567195432000 [label="rnn2.bias_hh_l0_reverse
 (768)" fillcolor=lightblue]
	2567195432000 -> 2567529256544
	2567529256544 [label=AccumulateGrad]
	2567529250880 -> 2567529259568
	2567529250880 [label=TBackward0]
	2567529256976 -> 2567529250880
	2567195428800 [label="linear2.weight
 (20, 512)" fillcolor=lightblue]
	2567195428800 -> 2567529256976
	2567529256976 [label=AccumulateGrad]
	2567529259280 -> 2566472302032
	2566386094128 [label="
 (10, 20)" fillcolor=darkolivegreen3]
	2567529259568 -> 2566386094128
	2566386094128 -> 2566472302032 [style=dotted]
}
